<!DOCTYPE html>
<html>



<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="DESCRIPTION META TAG">
    <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
    <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
    <meta property="og:url" content="URL OF THE WEBSITE" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />


    <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Robobench: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models as Embodied Brain</title>
    <link rel="icon" type="image/x-icon" href="static/images/log/R1.png">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">
    <link rel="stylesheet" href="static/css/table_style.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
    <script src="static/js/table.js"></script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">
                            <img src="static/images/log/R1.png">Robobench: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models as Embodied Brain
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            <span class="author-block">
                <a>Yulin Luo</a><sup>1,2*</sup>,</span>
                            <span class="author-block">
                <a>Chun-Kai Fan</a><sup>1*</sup>,</span>
                            <span class="author-block">
                <a>Menghang Dong</a><sup>1*</sup>,</span>
                            <span class="author-block">
                <a>Jiayu Shi</a><sup>1,2*</sup>,</span>
                            <span class="author-block">                
                <a>Mengdi Zhao</a><sup>3*</sup>,</span>
                            <span class="author-block">
                <a>Bo-Wen Zhang</a><sup>4*</sup>,</span>
                            <span class="author-block">
                <a>Jiaming Liu</a><sup>1</sup>,</span>
                            <span class="author-block">
                <a>Gaole Dai</a><sup>1</sup>,</span>
                            <span class="author-block">
                <a>Rongyu Zhang</a><sup>1</sup>,</span>
                            <span class="author-block">
                <a>Ruichuan An</a><sup>1</sup>,</span>
                            <span class="author-block">
                <a>Kun Wu</a><sup>5</sup>,</span>
                            <span class="author-block">
                <a>Zhengping Che</a><sup>5</sup>,</span>
                            <span class="author-block">
                <a>Shaoxuan Xie</a><sup>2</sup>,</span>
                            <span class="author-block">
                <a>Guocai Yao</a><sup>2</sup>,</span>
                            <span class="author-block">
                <a>Zhongxia Zhao</a><sup>1,2</sup>,</span>
                            <span class="author-block">
                <a>Pengwei Wang</a><sup>2</sup>,</span>
                            <span class="author-block">
                <a>Guang Liu</a><sup>2</sup>,</span>
                            <span class="author-block">
                <a>Zhongyuan Wang</a><sup>2</sup>,</span>
                            <span class="author-block">
                <a>Tiejun Huang</a><sup>1,2</sup>,</span>
                            <span class="author-block">
                <a>Cheng Chi</a><sup>2‚úâ</sup></span>
                            <span class="author-block">
                <a>Shanghang Zhang</a><sup>1,2‚úâ</sup></span>
                            <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank"></a></span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block" style="font-size: 0.9em;"><sup>1</sup> State Key Laboratory of Multimedia Information Processing, School of Computer Science, Peking University,<br><sup>2</sup> Beijing Academy of Artificial Intelligence, <sup>3</sup> Institute for Brain and Intelligence, Fudan University, <br><sup>4</sup> University of Science and Technology Beijing, <sup>5</sup> Beijing Innovation Center of Humanoid Robotics</span>
                            <span class="eql-cntrb"><small><br><sup>*</sup>Equal contribution, <sup>‚úâ</sup>Corresponding author</small><br></span>
                        </div>
                        
                        <img src="static/images/robobench_school_logos.png" width="100%" class="img-responsive">

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- Arxiv PDF link -->
                                <span class="link-block">
                        <a href="https://github.com/Robo-Bench/robo-bench.github.io" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                                <span>Paper</span>
                                </a>
                                </span>

                                <!-- Github link -->
                                <span class="link-block">
                    <a href="https://github.com/lyl750697268/RoboBench.git" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                                <span>Code</span>
                                </a>
                                </span>

                                <!-- ArXiv abstract Link -->
                                <span class="link-block">
                  <a href="https://huggingface.co/datasets/LeoFan01/RoboBench" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-database"></i>
                  </span>
                                <span>Dataset</span>
                                </a>
                                </span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- Teaser video-->
    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <img src="static/images/teaser/teaser.png">
                <h2 class="content has-text-justified">
                    <b>Overview of RoboBench.</b> We evaluates MLLMs as embodied brains across 5 dimensions, 14 subdimensions, and 25 tasks, with tasks color-coded by type <b>(top left)</b>. These dimensions follow the embodied execution pipeline <b>(bottom)</b>‚Äîfrom understanding intent, perceiving the environment, planning and adapting actions, refining subgoals via affordances, diagnosing failures‚Äîcapturing the core cognitive roles of System 2. Performance comparison <b>(top right)</b> highlights significant gaps among state-of-the-art MLLMs, with Gemini-2.5-Pro achieving the best results.
                </h2>
            </div>
        </div>
    </section>
    <!-- End teaser video -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <!-- <p> -->
                            Building robots that can perceive, reason, and act in dynamic, unstructured environments remains a core challenge. Recent embodied systems often adopt a dual-system paradigm, where System~2 handles high-level reasoning while System~1 executes low-level control. In this work, we refer to System~2 as the embodied brain, emphasizing its role as the cognitive core for reasoning and decision-making in manipulation tasks. Given this role, systematic evaluation of the embodied brain is essential for advancing robotic intelligence. Yet existing benchmarks emphasize execution success, or when targeting high-level reasoning, suffer from incomplete dimensions and limited task realism, offering only a partial picture of cognitive capability. To bridge this gap, we introduce RoboBench, a benchmark that systematically evaluates multimodal large language models (MLLMs) as embodied brains. Motivated by the critical roles across the full manipulation pipeline, RoboBench defines five dimensions‚Äîinstruction comprehension, perception reasoning, generalized planning, affordance prediction, and failure analysis‚Äîspanning 14 capabilities, 25 tasks, and 6092 QA pairs. To ensure realism, we curate datasets across diverse embodiments, attribute-rich objects, multi-view scenes, and memory-driven navigation, drawing from large-scale real robotic data and in-house collection. For planning, RoboBench introduces an evaluation framework that uses an MLLM as a world simulator. It moves beyond symbolic matching to evaluate embodied feasibility by simulating whether predicted plans can achieve critical object-state changes under physical and visual constraints, enabling faithful assessment of long-horizon reasoning. Experiments on 14 state-of-the-art MLLMs reveal fundamental limitations: difficulties with implicit instruction comprehension, spatiotemporal reasoning, cross-scenario planning, fine-grained affordance understanding, and execution failure diagnosis. RoboBench provides a comprehensive scaffold to quantify high-level cognition, clarify the role of the embodied brain, and guide the development of next-generation MLLMs toward more robust robotic intelligence.
                        <!-- </p> -->
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->

    <section class="hero is-small">
        <div class="hero-body">
            <div class="container">
                <h2 class="title is-3">News</h2>
                <div class="content has-text-justified">
                    <b>üî• 2025.10.21</b> - The paper, code, and dataset have been released‚ùóÔ∏è
                </div>
            </div>
        </div>
        </div>
    </section>

    <!-- <section class="hero is-small is-light">
        <div class="hero-body">
            <div class="container">
                <h2 class="title is-3">Takeaway</h2>
                <div class="content has-text-justified">Text</div>
            </div>
        </div>
        </div>
    </section> -->

    <section class="hero is-small">
        <div class="hero-body">
            <div class="container">
                <h2 class="title is-3">Highlight</h2>
                <div class="content has-text-justified">
                    <b>üîç Benchmark Overview</b><br>
                        <ul>
                            <li>The first comprehensive benchmark focused on evaluating MLLMs as embodied brains.</li>
                            <li>Systematic evaluation across 5 core dimensions, 14 capabilities, 25 task types, and 6,092 high-quality questions.</li>
                        </ul>
                    <b>üß≠ Comprehensive Dimensions</b><br>
                        <ul>
                            <li>Covers key embodied skills tailored to MLLM capabilities, including instruction comprehension, perception reasoning, generalized planning, affordance prediction, and failure analysis in real-world settings.</li>
                        </ul>
                    <b>üõ°Ô∏è Robust Evaluation</b><br>
                        <ul>
                            <li>All questions are manually verified for quality and consistency.</li>
                            <li>Long-horizon task planning is evaluated using a novel Directed Acyclic Graph (DAG)-guided approach to ensure rigor and robustness.</li>
                        </ul>
                    <b>üß† Real-world Data</b><br>
                        <ul>
                            <li>Built on the latest open-source real-robot datasets and proprietary real-world data.</li>
                            <li>Evaluation tasks are grounded in realistic embodied interaction scenarios.</li>
                        </ul>
                    <b>üåç Diverse Composition</b><br> 
                        <ul>
                            <li>Sourced from a wide range of data and scenarios.</li>
                            <li>Captures the complexity and diversity of real-world embodied tasks.</li>
                        </ul>
                </div>
            </div>
        </div>
        </div>
    </section>

    <section class="hero is-small is-light">
        <div class="hero-body">
            <div class="container">
                <!-- Paper video. -->
                <h2 class="title is-3">Leaderboard</h2>
                <div class="tab-container">
                    <div class="tab-buttons">
                        <button class="tab-btn active" data-tab="text-only">Embodied Perception Reasoning</button>
                        <button class="tab-btn" data-tab="closed-source">Embodied Instruction Comprehension & Embodied Generalized Planning</button>
                        <button class="tab-btn" data-tab="open-source">Embodied Affordance Reasoning & Embodied Failure Analysis</button>
                    </div>

                    <div id="text-only" class="tab-content active">
                        <table>
                            <thead>
                                <tr>
                                    <th rowspan="3" style="vertical-align: middle; text-align: center;">Model</th>
                                    <th colspan="9" style="vertical-align: middle; text-align: center;">Perception Reasoning</th>
                                </tr>
                                <tr>
                                    <th colspan="2" style="vertical-align: middle; text-align: center;">Robotic-centric</th>
                                    <th colspan="2" style="vertical-align: middle; text-align: center;">Object-centric</th>
                                    <th colspan="3" style="vertical-align: middle; text-align: center;">Scene-centric</th>
                                    <th style="vertical-align: middle; text-align: center;">Task-centric</th>
                                    <th rowspan="2" style="vertical-align: middle; text-align: center;">Avg</th>
                                </tr>
                                <tr>
                                    <th style="vertical-align: middle; text-align: center;">Robot-type<span class="sort-btn" data-col="0">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Robot-view<span class="sort-btn" data-col="1">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Static Attr.<span class="sort-btn" data-col="2">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Functional Attr.<span class="sort-btn" data-col="3">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Spatial Relation<span class="sort-btn" data-col="4">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Temp. Grounding<span class="sort-btn" data-col="5">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Causality<span class="sort-btn" data-col="6">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Refer. Comprehen.<span class="sort-btn" data-col="7">‚ñº</span></th>
                                </tr>
                            </thead>
                            <tbody>
                                <!-- <tr>
                                    <td>Total Number</td>
                                    <td>101</td>
                                    <td>101</td>
                                    <td>202</td>
                                    <td>117</td>
                                    <td>138</td>
                                    <td>309</td>
                                    <td>82</td>
                                    <td>101</td>
                                    <td>130</td>
                                    <td>145</td>
                                    <td>163</td>
                                    <td>1185</td>
                                </tr> -->
                                <tr>
                                    <th class="text-only" colspan="10">Basic Reference</th>
                                </tr>
                                <tr>
                                    <td>Human Evaluation</td>
                                    <td>80.67</td>
                                    <td>79.08</td>
                                    <td>43.77</td>
                                    <td>83.89</td>
                                    <td>70.91</td>
                                    <td>51.61</td>
                                    <td>91.22</td>
                                    <td>93.22</td>
                                    <td>74.30</td>
                                </tr>
                                <tr>
                                    <td>GPT-4o-text-only</td>
                                    <td>20.51</td>
                                    <td>13.77</td>
                                    <td>5.18</td>
                                    <td>35.37</td>
                                    <td>25.74</td>
                                    <td>18.32</td>
                                    <td>25.52</td>
                                    <td>22.09</td>
                                    <td>20.81</td>
                                </tr>
                                <tr>
                                    <th class="text-only" colspan="10">Closed-Source MLLMs</th>
                                </tr>
                                <tr>
                                    <td>GPT-4o-Mini</td>
                                    <td>38.75</td>
                                    <td>18.84</td>
                                    <td>26.43</td>
                                    <td>53.66</td>
                                    <td>30.36</td>
                                    <td>22.65</td>
                                    <td>34.25</td>
                                    <td>39.67</td>
                                    <td>33.08</td>
                                </tr>
                                <tr>
                                    <td>GPT-4o</td>
                                    <td><strong>64.96</strong></td>
                                    <td>39.38</td>
                                    <td>24.92</td>
                                    <td>46.75</td>
                                    <td>42.24</td>
                                    <td>20.61</td>
                                    <td>33.10</td>
                                    <td>41.31</td>
                                    <td>39.16</td>
                                </tr>
                                <tr>
                                    <td>Claude-3.5-Sonnet</td>
                                    <td>41.31</td>
                                    <td>36.23</td>
                                    <td>29.13</td>
                                    <td>62.60</td>
                                    <td>34.98</td>
                                    <td>21.88</td>
                                    <td>36.09</td>
                                    <td>25.36</td>
                                    <td>35.95</td>
                                </tr>
                                <tr>
                                    <td>Claude-3.7-Sonnet</td>
                                    <td>40.46</td>
                                    <td>32.37</td>
                                    <td>45.20</td>
                                    <td>71.14</td>
                                    <td>36.63</td>
                                    <td>21.09</td>
                                    <td>40.92</td>
                                    <td>28.02</td>
                                    <td>39.48</td>
                                </tr>
                                <tr>
                                    <td>Gemini-2.0-Flash</td>
                                    <td>56.69</td>
                                    <td>20.77</td>
                                    <td>49.08</td>
                                    <td><u>78.46</u></td>
                                    <td>42.57</td>
                                    <td>21.37</td>
                                    <td>51.72</td>
                                    <td>72.40</td>
                                    <td>49.13</td>
                                </tr>
                                <tr>
                                    <td>Gemini-2.5-Flash</td>
                                    <td>62.39</td>
                                    <td>39.38</td>
                                    <td><strong>55.02</strong></td>
                                    <td>77.24</td>
                                    <td><u>57.43</u></td>
                                    <td><u>33.58</u></td>
                                    <td><u>70.34</u></td>
                                    <td><u>74.64</u></td>
                                    <td><u>58.75</u></td>
                                </tr>
                                <tr>
                                    <td>Gemini-2.5-Pro</td>
                                    <td><u>64.30</u></td>
                                    <td>41.71</td>
                                    <td><u>54.83</u></td>
                                    <td><strong>82.27</strong></td>
                                    <td><strong>60.44</strong></td>
                                    <td><strong>49.68</strong></td>
                                    <td><strong>71.73</strong></td>
                                    <td><strong>78.68</strong></td>
                                    <td><strong>62.96</strong></td>
                                </tr>
                                <tr>
                                    <td>Qwen-VL-Plus</td>
                                    <td>28.21</td>
                                    <td>21.74</td>
                                    <td>34.63</td>
                                    <td>58.54</td>
                                    <td>27.72</td>
                                    <td>21.37</td>
                                    <td>31.03</td>
                                    <td>34.36</td>
                                    <td>32.20</td>
                                </tr>
                                <tr>
                                    <td>Qwen-VL-Max</td>
                                    <td>47.86</td>
                                    <td><strong>43.48</strong></td>
                                    <td>39.70</td>
                                    <td>75.20</td>
                                    <td>50.17</td>
                                    <td>27.45</td>
                                    <td>37.93</td>
                                    <td>41.53</td>
                                    <td>45.42</td>
                                </tr>
                                <tr>
                                    <th class="text-only" colspan="10">Open-Source Multi-Image MLLMs</th>
                                </tr>
                                <tr>
                                    <td>LLaVA-OneVision-0.5B</td>
                                    <td>30.34</td>
                                    <td>23.68</td>
                                    <td>37.08</td>
                                    <td>49.66</td>
                                    <td>27.27</td>
                                    <td>18.42</td>
                                    <td>23.65</td>
                                    <td>19.21</td>
                                    <td>28.66</td>
                                </tr>
                                <tr>
                                    <td>LLaVA-OneVision-7B</td>
                                    <td>44.83</td>
                                    <td>30.26</td>
                                    <td>33.43</td>
                                    <td>75.84</td>
                                    <td>45.45</td>
                                    <td>23.68</td>
                                    <td>25.68</td>
                                    <td>44.63</td>
                                    <td>40.48</td>
                                </tr>
                                <tr>
                                    <td>Qwen2.5-VL-7B-Ins</td>
                                    <td>23.93</td>
                                    <td>26.81</td>
                                    <td>37.86</td>
                                    <td>46.34</td>
                                    <td>31.68</td>
                                    <td>22.90</td>
                                    <td>14.48</td>
                                    <td>36.81</td>
                                    <td>30.10</td>
                                </tr>
                                <tr>
                                    <td>Qwen2.5-VL-72B-Ins</td>
                                    <td>47.72</td>
                                    <td><u>42.75</u></td>
                                    <td>41.74</td>
                                    <td>72.95</td>
                                    <td>48.51</td>
                                    <td>27.87</td>
                                    <td>40.32</td>
                                    <td>42.13</td>
                                    <td>45.50</td>
                                </tr>
                                <tr>
                                    <th class="text-only" colspan="10">Embodied MLLMs</th>
                                </tr>
                                <tr>
                                    <td>RoboBrain-2.0-7B</td>
                                    <td>44.97</td>
                                    <td>24.84</td>
                                    <td>40.43</td>
                                    <td>79.19</td>
                                    <td>48.18</td>
                                    <td>23.48</td>
                                    <td>41.22</td>
                                    <td>53.67</td>
                                    <td>44.50</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>

                    <div id="closed-source" class="tab-content">
                        <table>
                            <thead>
                                <tr>
                                    <th rowspan="3" style="vertical-align: middle; text-align: center;">Model</th>
                                    <th colspan="3" style="vertical-align: middle; text-align: center;">Instruction Comprehension</th>
                                    <th colspan="11" style="vertical-align: middle; text-align: center;">Generalized Planning</th>
                                </tr>
                                <tr>
                                    <th style="vertical-align: middle; text-align: center;">Explicit<span class="sort-btn" data-col="0">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Implicit<span class="sort-btn" data-col="1">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Avg<span class="sort-btn" data-col="2">‚ñº</span></th>
                                    <th colspan="4" style="vertical-align: middle; text-align: center;">Cross-Embodiment Planning</th>
                                    <th colspan="3" style="vertical-align: middle; text-align: center;">Cross-Object Planning</th>
                                    <th colspan="2" style="vertical-align: middle; text-align: center;">Cross-View Planning</th>
                                    <th style="vertical-align: middle; text-align: center;">Cross-Task Planning</th>
                                    <th style="vertical-align: middle; text-align: center;">Avg</th>
                                </tr>
                                <tr>
                                    <th colspan="3"></th>
                                    <th style="vertical-align: middle; text-align: center;">Single-arm<span class="sort-btn" data-col="3">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Dual-arm<span class="sort-btn" data-col="4">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Mobile-manip.<span class="sort-btn" data-col="5">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Human<span class="sort-btn" data-col="6">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Material Afford.<span class="sort-btn" data-col="7">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Physical Attr.<span class="sort-btn" data-col="8">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">World Knowl.<span class="sort-btn" data-col="9">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Multi<span class="sort-btn" data-col="10">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Single<span class="sort-btn" data-col="11">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Navigation Plan.<span class="sort-btn" data-col="12">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;"></th>
                                </tr>
                            </thead>
                            <tbody>
                                <!-- <tr>
                                    <td>ÊúÄÁªàÊï∞Èáè</td>
                                    <td>136</td>
                                    <td>164</td>
                                    <td>54</td>
                                    <td>126</td>
                                    <td>58</td>
                                    <td>131</td>
                                    <td>100</td>
                                    <td>122</td>
                                    <td>106</td>
                                    <td>71</td>
                                    <td>111</td>
                                    <td>100</td>
                                    <td>65</td>
                                    <td>38</td>
                                    <td>85</td>
                                    <td>86</td>
                                </tr> -->
                                <tr>
                                    <th class="closed-source" colspan="15">Basic Reference</th>
                                </tr>
                                <tr>
                                    <td>Human Evaluation</td>
                                    <td>59.94</td>
                                    <td>61.13</td>
                                    <td>60.54</td>
                                    <td>72.50</td>
                                    <td>41.93</td>
                                    <td>41.55</td>
                                    <td>62.28</td>
                                    <td>56.70</td>
                                    <td>58.98</td>
                                    <td>49.36</td>
                                    <td>52.82</td>
                                    <td>51.59</td>
                                    <td>45.23</td>
                                    <td>54.50</td>
                                </tr>
                                <tr>
                                    <td>GPT-4o-text-only</td>
                                    <td>38.80</td>
                                    <td>11.10</td>
                                    <td>24.95</td>
                                    <td>26.70</td>
                                    <td>33.32</td>
                                    <td>43.65</td>
                                    <td>37.86</td>
                                    <td>36.58</td>
                                    <td>22.33</td>
                                    <td>37.68</td>
                                    <td>44.35</td>
                                    <td>38.11</td>
                                    <td>36.90</td>
                                    <td>33.95</td>
                                </tr>
                                <tr>
                                    <th class="closed-source" colspan="15">Closed-Source MLLMs</th>
                                </tr>
                                <tr>
                                    <td>GPT-4o-Mini</td>
                                    <td>41.21</td>
                                    <td>14.95</td>
                                    <td>28.08</td>
                                    <td>27.47</td>
                                    <td>25.21</td>
                                    <td>37.98</td>
                                    <td>31.72</td>
                                    <td>33.75</td>
                                    <td>38.46</td>
                                    <td>42.56</td>
                                    <td>39.11</td>
                                    <td>33.29</td>
                                    <td>34.04</td>
                                    <td>33.31</td>
                                </tr>
                                <tr>
                                    <td>GPT-4o</td>
                                    <td>45.60</td>
                                    <td><u>19.04</u></td>
                                    <td>32.32</td>
                                    <td>28.28</td>
                                    <td>32.65</td>
                                    <td><strong>52.69</strong></td>
                                    <td>35.71</td>
                                    <td>39.93</td>
                                    <td>46.09</td>
                                    <td>41.34</td>
                                    <td>38.51</td>
                                    <td>33.66</td>
                                    <td>39.41</td>
                                    <td>37.74</td>
                                </tr>
                                <tr>
                                    <td>Claude-3.5-Sonnet</td>
                                    <td>42.11</td>
                                    <td>14.85</td>
                                    <td>28.48</td>
                                    <td><strong>30.18</strong></td>
                                    <td>33.65</td>
                                    <td>50.29</td>
                                    <td><strong>41.05</strong></td>
                                    <td>38.28</td>
                                    <td>40.67</td>
                                    <td>39.63</td>
                                    <td>45.95</td>
                                    <td>40.43</td>
                                    <td>39.77</td>
                                    <td>38.07</td>
                                </tr>
                                <tr>
                                    <td>Claude-3.7-Sonnet</td>
                                    <td><u>47.77</u></td>
                                    <td>14.53</td>
                                    <td>31.15</td>
                                    <td><u>29.86</u></td>
                                    <td><u>38.69</u></td>
                                    <td>50.39</td>
                                    <td>37.06</td>
                                    <td>38.65</td>
                                    <td>41.86</td>
                                    <td><strong>51.83</strong></td>
                                    <td><strong>48.19</strong></td>
                                    <td><u>44.51</u></td>
                                    <td><u>39.95</u></td>
                                    <td><u>41.68</u></td>
                                </tr>
                                <tr>
                                    <td>Gemini-2.0-Flash</td>
                                    <td>43.49</td>
                                    <td>16.38</td>
                                    <td>29.93</td>
                                    <td>28.67</td>
                                    <td>33.66</td>
                                    <td>48.27</td>
                                    <td>33.95</td>
                                    <td>40.76</td>
                                    <td>54.27</td>
                                    <td>40.12</td>
                                    <td>46.13</td>
                                    <td>40.73</td>
                                    <td>37.02</td>
                                    <td>38.62</td>
                                </tr>
                                <tr>
                                    <td>Gemini-2.5-Flash</td>
                                    <td>42.53</td>
                                    <td>17.10</td>
                                    <td>29.82</td>
                                    <td>27.05</td>
                                    <td>40.46</td>
                                    <td>49.91</td>
                                    <td>34.50</td>
                                    <td>39.87</td>
                                    <td>53.37</td>
                                    <td>46.22</td>
                                    <td>39.41</td>
                                    <td>43.29</td>
                                    <td>38.32</td>
                                    <td>39.33</td>
                                </tr>
                                <tr>
                                    <td>Gemini-2.5-Pro</td>
                                    <td>51.15</td>
                                    <td>19.60</td>
                                    <td>35.37</td>
                                    <td>29.71</td>
                                    <td>37.65</td>
                                    <td>50.96</td>
                                    <td>37.44</td>
                                    <td>39.29</td>
                                    <td>56.50</td>
                                    <td>43.29</td>
                                    <td>47.35</td>
                                    <td>45.12</td>
                                    <td>43.62</td>
                                    <td>41.81</td>
                                </tr>
                                <tr>
                                    <td>Qwen-VL-Plus</td>
                                    <td>37.77</td>
                                    <td>10.38</td>
                                    <td>24.07</td>
                                    <td>24.68</td>
                                    <td>21.75</td>
                                    <td>32.98</td>
                                    <td>33.91</td>
                                    <td>28.45</td>
                                    <td>33.55</td>
                                    <td>33.78</td>
                                    <td>30.95</td>
                                    <td>28.60</td>
                                    <td>4.39</td>
                                    <td>26.77</td>
                                </tr>
                                <tr>
                                    <td>Qwen-VL-Max</td>
                                    <td>46.45</td>
                                    <td>16.98</td>
                                    <td>31.71</td>
                                    <td>28.30</td>
                                    <td>35.73</td>
                                    <td>47.79</td>
                                    <td>32.40</td>
                                    <td>40.44</td>
                                    <td>44.33</td>
                                    <td>42.32</td>
                                    <td>41.79</td>
                                    <td>37.68</td>
                                    <td>38.00</td>
                                </tr>
                                <tr>
                                    <th class="closed-source" colspan="15">Open-Source Multi-Image MLLMs</th>
                                </tr>
                                <tr>
                                    <td>LLaVA-OneVision-0.5B</td>
                                    <td>6.82</td>
                                    <td>1.24</td>
                                    <td>3.61</td>
                                    <td>2.90</td>
                                    <td>4.57</td>
                                    <td>4.77</td>
                                    <td>3.68</td>
                                    <td>4.77</td>
                                    <td>3.47</td>
                                    <td>6.47</td>
                                    <td>4.30</td>
                                    <td>3.62</td>
                                    <td>11.39</td>
                                    <td>4.83</td>
                                </tr>
                                <tr>
                                    <td>LLaVA-OneVision-7B</td>
                                    <td>18.93</td>
                                    <td>3.48</td>
                                    <td>10.05</td>
                                    <td>11.48</td>
                                    <td>16.23</td>
                                    <td>8.27</td>
                                    <td>5.34</td>
                                    <td>18.51</td>
                                    <td>15.62</td>
                                    <td>8.10</td>
                                    <td>0.00</td>
                                    <td>15.16</td>
                                    <td>24.67</td>
                                    <td>12.15</td>
                                </tr>
                                <tr>
                                    <td>Qwen2.5-VL-7B-Ins</td>
                                    <td>26.45</td>
                                    <td>4.65</td>
                                    <td>15.55</td>
                                    <td>19.47</td>
                                    <td>12.90</td>
                                    <td>28.75</td>
                                    <td>28.19</td>
                                    <td>22.06</td>
                                    <td>21.63</td>
                                    <td>25.61</td>
                                    <td>11.79</td>
                                    <td>20.12</td>
                                    <td>2.10</td>
                                    <td>18.64</td>
                                </tr>
                                <tr>
                                    <td>Qwen2.5-VL-72B-Ins</td>
                                    <td>46.81</td>
                                    <td>15.15</td>
                                    <td>30.98</td>
                                    <td>28.20</td>
                                    <td>36.92</td>
                                    <td>49.14</td>
                                    <td>31.31</td>
                                    <td>40.51</td>
                                    <td>44.94</td>
                                    <td>38.90</td>
                                    <td>43.16</td>
                                    <td>40.24</td>
                                    <td>37.47</td>
                                    <td>37.73</td>
                                </tr>
                                <tr>
                                    <th class="closed-source" colspan="15">Embodied MLLMs</th>
                                </tr>
                                <tr>
                                    <td>RoboBrain-2.0-7B</td>
                                    <td>36.93</td>
                                    <td>8.19</td>
                                    <td>22.51</td>
                                    <td>15.46</td>
                                    <td>25.32</td>
                                    <td>32.72</td>
                                    <td>31.81</td>
                                    <td>19.85</td>
                                    <td>30.85</td>
                                    <td>23.24</td>
                                    <td>31.51</td>
                                    <td>23.89</td>
                                    <td>24.53</td>
                                    <td>25.35</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>

                    <div id="open-source" class="tab-content">
                        <table>
                            <thead>
                                <tr>
                                    <th rowspan="2" style="vertical-align: middle; text-align: center;">Model</th>
                                    <th colspan="4" style="vertical-align: middle; text-align: center;">Affordance Prediction</th>
                                    <th colspan="3" style="vertical-align: middle; text-align: center;">Failure Analysis</th>
                                </tr>
                                <tr>
                                    <th style="vertical-align: middle; text-align: center;">Static<span class="sort-btn" data-col="0">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Dynamic<span class="sort-btn" data-col="1">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Naviga.<span class="sort-btn" data-col="2">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Avg<span class="sort-btn" data-col="3">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Execution<span class="sort-btn" data-col="4">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Planning<span class="sort-btn" data-col="5">‚ñº</span></th>
                                    <th style="vertical-align: middle; text-align: center;">Avg<span class="sort-btn" data-col="6">‚ñº</span></th>
                                </tr>
                            </thead>
                            <tbody>
                                <!-- <tr>
                                    <td>ÊúÄÁªàÊï∞Èáè</td>
                                    <td>150</td>
                                    <td>151</td>
                                    <td>102</td>
                                    <td>151</td>
                                    <td>145</td>
                                </tr> -->
                                <tr>
                                    <th class="open-source" colspan="8">Basic Reference</th>
                                </tr>
                                <tr>
                                    <td>Human Evaluation</td>
                                    <td>86.08</td>
                                    <td>80.02</td>
                                    <td>81.85</td>
                                    <td>82.63</td>
                                    <td>47.30</td>
                                    <td>80.67</td>
                                    <td>63.99</td>
                                </tr>
                                <tr>
                                    <td>GPT-4o-text-only</td>
                                    <td>44.89</td>
                                    <td>40.70</td>
                                    <td>38.19</td>
                                    <td>39.88</td>
                                    <td>25.17</td>
                                    <td>37.93</td>
                                    <td>31.55</td>
                                </tr>
                                <tr>
                                    <th class="open-source" colspan="8">Closed-Source MLLMs</th>
                                </tr>
                                <tr>
                                    <td>GPT-4o-Mini</td>
                                    <td>50.64</td>
                                    <td>42.88</td>
                                    <td>42.30</td>
                                    <td>46.39</td>
                                    <td>17.66</td>
                                    <td>44.60</td>
                                    <td>31.13</td>
                                </tr>
                                <tr>
                                    <td>GPT-4o</td>
                                    <td>55.61</td>
                                    <td>49.14</td>
                                    <td>49.91</td>
                                    <td>51.91</td>
                                    <td>22.29</td>
                                    <td>57.01</td>
                                    <td>39.65</td>
                                </tr>
                                <tr>
                                    <td>Claude-3.5-Sonnet</td>
                                    <td>56.26</td>
                                    <td>54.25</td>
                                    <td>53.84</td>
                                    <td>54.77</td>
                                    <td>16.12</td>
                                    <td>47.52</td>
                                    <td>31.82</td>
                                </tr>
                                <tr>
                                    <td>Claude-3.7-Sonnet</td>
                                    <td>60.02</td>
                                    <td>52.38</td>
                                    <td>50.07</td>
                                    <td>54.06</td>
                                    <td>18.32</td>
                                    <td>54.24</td>
                                    <td>36.28</td>
                                </tr>
                                <tr>
                                    <td>Gemini-2.0-Flash</td>
                                    <td>61.65</td>
                                    <td>61.76</td>
                                    <td>66.89</td>
                                    <td>63.37</td>
                                    <td>28.48</td>
                                    <td>59.80</td>
                                    <td>44.14</td>
                                </tr>
                                <tr>
                                    <td>Gemini-2.5-Flash</td>
                                    <td>61.20</td>
                                    <td>52.04</td>
                                    <td>52.01</td>
                                    <td>54.29</td>
                                    <td>18.54</td>
                                    <td>67.65</td>
                                    <td>43.10</td>
                                </tr>
                                <tr>
                                    <td>Gemini-2.5-Pro</td>
                                    <td>70.54</td>
                                    <td>62.03</td>
                                    <td>63.96</td>
                                    <td>65.21</td>
                                    <td>15.96</td>
                                    <td>74.31</td>
                                    <td>45.14</td>
                                </tr>
                                <tr>
                                    <td>Qwen-VL-Plus</td>
                                    <td>51.74</td>
                                    <td>37.42</td>
                                    <td>47.97</td>
                                    <td>48.18</td>
                                    <td>13.91</td>
                                    <td>40.00</td>
                                    <td>26.96</td>
                                </tr>
                                <tr>
                                    <td>Qwen-VL-Max</td>
                                    <td>70.01</td>
                                    <td>56.26</td>
                                    <td>50.85</td>
                                    <td>59.43</td>
                                    <td>17.22</td>
                                    <td>57.93</td>
                                    <td>37.58</td>
                                </tr>
                                <tr>
                                    <th class="open-source" colspan="8">Open-Source Multi-Image MLLMs</th>
                                </tr>
                                <tr>
                                    <td>LLaVA-OneVision-0.5B</td>
                                    <td>20.56</td>
                                    <td>28.56</td>
                                    <td>27.69</td>
                                    <td>24.76</td>
                                    <td>21.19</td>
                                    <td>24.67</td>
                                    <td>22.93</td>
                                </tr>
                                <tr>
                                    <td>LLaVA-OneVision-7B</td>
                                    <td>23.83</td>
                                    <td>33.61</td>
                                    <td>33.43</td>
                                    <td>30.29</td>
                                    <td>29.14</td>
                                    <td>34.00</td>
                                    <td>31.56</td>
                                </tr>
                                <tr>
                                    <td>Qwen2.5-VL-7B-Ins</td>
                                    <td>49.73</td>
                                    <td>38.03</td>
                                    <td>42.16</td>
                                    <td>43.15</td>
                                    <td>13.91</td>
                                    <td>26.90</td>
                                    <td>20.41</td>
                                </tr>
                                <tr>
                                    <td>Qwen2.5-VL-72B-Ins</td>
                                    <td>71.54</td>
                                    <td>51.94</td>
                                    <td>47.67</td>
                                    <td>56.67</td>
                                    <td>12.59</td>
                                    <td>50.72</td>
                                    <td>31.66</td>
                                </tr>
                                <tr>
                                    <th class="open-source" colspan="8">Embodied MLLMs</th>
                                </tr>
                                <tr>
                                    <td>RoboBrain-2.0-7B</td>
                                    <td>51.87</td>
                                    <td>54.63</td>
                                    <td>41.61</td>
                                    <td>49.37</td>
                                    <td>7.95</td>
                                    <td>42.00</td>
                                    <td>41.24</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
                <div class="container is-max-desktop"></div>
                <div class="content has-text-justified">

                </div>
            </div>
        </div>
        </div>
    </section>

    <!-- Key Findings Section -->
    <section class="hero is-small is-light">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <h2 class="title is-3">Key Findings from RoboBench Evaluation</h2>
                <div class="content has-text-justified">
                    
                    <!-- Overall Findings -->
                    <h3 class="title is-4 has-text-centered" style="margin-bottom: 1.5rem;">Overall Findings</h3>
                    <div class="columns is-multiline">
                        <div class="column is-5">
                            <div class="box" style="height: 100%;">
                                <h4 class="title is-6 has-text-primary">ü•á Gemini-2.5-Pro Leads but Still Trails Humans</h4>
                                <p style="font-size: 0.9em;">Gemini-2.5-Pro achieves the strongest overall performance across all five cognitive dimensions. It notably scores <strong>62.96</strong> in perception reasoning and <strong>65.21 / 45.14</strong> in affordance and failure analysis‚Äîwell above other models but <strong>still far below human levels (74.30 / 82.63 / 63.99)</strong>. This underscores a persistent gap between current MLLMs and robust human-level embodied intelligence.</p>
                            </div>
                        </div>
                        
                        <div class="column is-5 is-offset-1">
                            <div class="box" style="height: 100%;">
                                <h4 class="title is-6 has-text-primary">üîí Closed-Source Models Still Hold the Advantage</h4>
                                <p style="font-size: 0.9em;">Closed-source MLLMs outperform open-source ones in <strong>four out of five</strong> dimensions, often by <strong>10‚Äì15%</strong>. Open-source models only approach parity in perception reasoning. Within each family, <strong>larger models consistently perform better</strong>, e.g., GPT-4o > GPT-4o-mini, Claude-3.7 > Claude-3.5.</p>
                            </div>
                        </div>
                        
                        <div class="column is-5">
                            <div class="box" style="height: 100%;">
                                <h4 class="title is-6 has-text-primary">ü§ñ Embodied Training Brings Noticeable Gains</h4>
                                <p style="font-size: 0.9em;">The <strong>embodied MLLM RoboBrain-2.0-7B</strong> surpasses similarly sized general open-source models in <strong>perception reasoning</strong>, <strong>planning</strong>, and <strong>affordance prediction</strong>. This validates the effectiveness of <strong>domain-specific embodied datasets</strong> for improving multimodal reasoning and planning.</p>
                            </div>
                        </div>
                        
                        <div class="column is-5 is-offset-1">
                            <div class="box" style="height: 100%;">
                                <h4 class="title is-6 has-text-primary">üìä Cognitive Difficulty Varies Across Dimensions</h4>
                                <p style="font-size: 0.9em;"><strong>Perception reasoning</strong> yields the highest accuracies; <strong>Generalized planning</strong> remains the most challenging, exposing weaknesses in long-horizon reasoning and structured task decomposition. The contrast highlights where <strong>future progress</strong> is most needed.</p>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Fine-grained Findings -->
                    <h3 class="title is-4 has-text-centered" style="margin-top: 2rem; margin-bottom: 1.5rem;">Fine-grained Findings</h3>
                    <div class="columns is-multiline">
                        <div class="column is-5">
                            <div class="box" style="height: 100%;">
                                <h4 class="title is-6 has-text-primary">üß† Implicit Intent Understanding Remains a Major Challenge</h4>
                                <p style="font-size: 0.9em;">Performance on <strong>implicit instructions</strong> drops by about <strong>30%</strong> compared to explicit ones. Models struggle to infer goals from indirect human demands, revealing weak integration of <strong>language, perception, and context</strong>.</p>
                            </div>
                        </div>
                        
                        <div class="column is-5 is-offset-1">
                            <div class="box" style="height: 100%;">
                                <h4 class="title is-6 has-text-primary">üëÅÔ∏è Perception and Temporal Reasoning Bottlenecks</h4>
                                <p style="font-size: 0.9em;">Models misidentify robot types or viewpoints and fail to localize events in time. Temporal and causal reasoning accuracies hover around <strong>30‚Äì40%</strong>, except for Gemini series. Stronger <strong>embodiment-aware perception</strong> and <strong>spatiotemporal reasoning</strong> modules are needed.</p>
                            </div>
                        </div>
                        
                        <div class="column is-5">
                            <div class="box" style="height: 100%;">
                                <h4 class="title is-6 has-text-primary">üß© Planning Limitations Persist</h4>
                                <p style="font-size: 0.9em;"><strong>Cross-embodiment:</strong> poor coordination in dual-arm or mobile manipulation. <strong>Cross-object:</strong> difficulty with rare or knowledge-dependent objects. <strong>Cross-view:</strong> multi-image inputs markedly improve performance (e.g., +5‚Äì7 points for GPT-4o / Claude-3.7), showing the promise of multi-view reasoning.</p>
                            </div>
                        </div>
                        
                        <div class="column is-5 is-offset-1">
                            <div class="box" style="height: 100%;">
                                <h4 class="title is-6 has-text-primary">‚öôÔ∏è Failure Analysis Is Extremely Hard</h4>
                                <p style="font-size: 0.9em;">Diagnosing <strong>execution-level errors</strong> is far more difficult than planning-level ones (scores 10‚Äì20 vs. 40‚Äì60). Requires <strong>fine-grained spatial and physical understanding</strong> (e.g., distinguishing location vs. rotation errors). Even humans achieve only <strong>47.3</strong> on such tasks, underscoring their intrinsic complexity.</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero is-small">
        <div class="hero-body">
            <div class="container">
                <!-- Paper video. -->
                <h2 class="title is-3">Dataset Construction Pipeline</h2>
                <div class="columns is-centered has-text-centered">
                    <img src="static/images/pipeline/pipeline.png">
                </div>
                <div class="container is-max-desktop"></div>
                <div class="content has-text-justified">
                    <b>Dataset Construction Pipeline.</b> RoboBench integrates open-source and self-collected robot data under a shared process‚Äîpreprocessing ‚Üí tool-assisted + human-in-the-loop annotation ‚Üí unified schema ‚Üí auto-generated QA‚Äîand builds datasets for five dimensions: <b>Instruction Comprehension:</b> pair explicit instructions with LLM-rewritten implicit variants to test intent understanding. <b>Perception Reasoning:</b> use captioning/detection/segmentation tools to draft labels across robotic/object/scene/task views, then human-refine and standardize. <b>Generalized Planning:</b> construct a planning pool from robot videos; VLMs produce step/timestamp summaries and metadata, which are mapped to function templates to support Q1/Q2/Q3 evaluations. <b>Affordance Prediction:</b> sample key frames and annotate static (contact points), dynamic (trajectories), and mobile (base positions) affordances. <b>Failure Analysis:</b> mine execution-level failures from real trials and synthesize planning-level errors by perturbing correct instructions. All outputs follow one schema and are rendered into binary, single-choice, and multi-step multiple-choice QA formats for open- and closed-source MLLMs.
                </div>
            </div>
        </div>
        </div>
    </section>

     <!-- Planning Evaluation Pipeline -->
     <section class="hero is-small">
     <div class="hero-body">
         <div class="container">
             <h2 class="title is-3">Planning Evaluation Pipeline</h2>
             <div class="columns is-centered">
                 <div class="column is-four-fifths">
                     <div class="has-text-centered">
                         <img src="static/images/eval_pipeline/eval_pipeline.png" alt="Planning Evaluation Pipeline" width="100%"/>
                     </div>
                     <div class="content has-text-left" style="margin-top: 1rem;">
                         <p style="font-size: 1.1em;">
                             <b>Planning Evaluation Framework.</b> Evaluation of the planning dimension (Q1‚ÄìQ3). Each task is decomposed into a sequence of parameterized atomic actions forming a Directed Acyclic Graph (DAG) that encodes causal and temporal dependencies. For <b>Q1 (Long-horizon planning)</b>, an MLLM-based world simulator assesses both NodeCorrectness (action alignment) and TaskCompletion (goal-state achievement) by simulating action rollouts under visual and physical constraints. <b>Q2 (Next-step planning)</b> evaluates fine-grained step prediction by comparing skill, object, and parameter accuracy, while <b>Q3 (Task state estimation)</b> measures binary correctness on whether a subtask has been completed. Together, the pipeline provides a unified, interpretable framework for assessing structural correctness and embodied feasibility in planning.
                         </p>
                     </div>
                 </div>
             </div>
         </div>
     </div>
     </section>

   <!-- Case Study -->
   <section class="section" id="case-study" style="padding-top:2rem;">
     <div class="container is-max-desktop">
       <h2 class="title is-3" style="text-align:center; margin-bottom:1rem; font-size: 2.3em;">Demo Case</h2>
       <br>
         <div class="columns is-centered has-text-centered">
             <div class="column is-four-fifths">
                 <img src="static/images/demo_case/demo_case.png" alt="Demo Case" width="100%"/>
             </div>
         </div>
     </div>
   </section>

     <!-- Paper poster -->
    <!-- <section class="hero is-small is-light">
        <div class="hero-body">
            <div class="container">
                <h2 class="title">Poster</h2>

                <iframe src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>

            </div>
        </div>
    </section> -->
    <!--End paper poster -->


    <!--BibTex citation -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@misc{luo2025robobench,
        title={Robobench: A Comprehensive Evaluation Benchmark for Perception, Planning and Reflection of Embodied Multimodal Large Language Models}, 
        author={Yulin Luo, Chun-Kai Fan, Menghang Dong, Mengdi Zhao, Bo-Wen Zhang, Jiayu Shi, Jiaming Liu, Gaole Dai, Rongyu Zhang, Ruichuan An, Kun Wu, Zhengping Che, Pengwei Wang, Guang Liu, Zhongyuan Wang, Tiejun Huang, Shanghang Zhang},
        year={2025},
        eprint={xxx},
        archivePrefix={arXiv},
        primaryClass={xxx},
        url={https://arxiv.org/abs/xxx}, 
  }</code></pre>
        </div>
    </section>
    <!--End BibTex citation -->


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">

                        <p>
                            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project
                            page. You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"
                                target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>